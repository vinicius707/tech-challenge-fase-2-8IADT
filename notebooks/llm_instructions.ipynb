{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Gerar Instruções via LLM (ou fallback)\n\nEste notebook demonstra como gerar `instruction.txt` a partir dos artefatos do run usando o adapter LLM (OpenAI quando disponível; fallback caso contrário)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Selecionar run e executar geração"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Selecionar último run\nimport glob\nrun_dir = sorted(glob.glob('experiments/run_*'))[-1]\nprint('Using run:', run_dir)\n\n# Gerar instruções (usa experiments/prompts/route_instructions_prompt.txt se existir)\n!PYTHONPATH=. python3 scripts/generate_instructions.py {run_dir}\n\n# Mostrar instrução gerada\nwith open(run_dir + '/instruction.txt','r',encoding='utf-8') as f:\n    print(f.read()[:1000])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Dicas sobre uso de OpenAI\n\n- Para usar a API do OpenAI, defina `OPENAI_API_KEY` como variável de ambiente antes de executar o notebook. Se não definida, o adapter usa um fallback legível."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}
